{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgNDp4lYmEkjHP8Iv+WaIO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "85898e3c2ae74b6f8e8198ff15b9f09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d1c013f3e9f456cb8e9801e119027aa",
              "IPY_MODEL_3bb7bf9be2674494842ad6b726d1f61d",
              "IPY_MODEL_8295191b1da1436e95f15eb5edd14c98"
            ],
            "layout": "IPY_MODEL_96f914e5c5d64de48ecaa0b1eeac2a03"
          }
        },
        "0d1c013f3e9f456cb8e9801e119027aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db169823b7f24168857cf22eee1fea74",
            "placeholder": "​",
            "style": "IPY_MODEL_ea3607e5e36b4f8dbd9b07f0ed953ff0",
            "value": "Downloading: 100%"
          }
        },
        "3bb7bf9be2674494842ad6b726d1f61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ca22facc1264260958e09346feefd56",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aeb5e47bed2f460db7b17ed84b9776a5",
            "value": 26
          }
        },
        "8295191b1da1436e95f15eb5edd14c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e91d9e4adbfe42bba99a24106c9da588",
            "placeholder": "​",
            "style": "IPY_MODEL_9689e11b042d4808be5ccd7be504c0b6",
            "value": " 26.0/26.0 [00:00&lt;00:00, 559B/s]"
          }
        },
        "96f914e5c5d64de48ecaa0b1eeac2a03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db169823b7f24168857cf22eee1fea74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea3607e5e36b4f8dbd9b07f0ed953ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ca22facc1264260958e09346feefd56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb5e47bed2f460db7b17ed84b9776a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e91d9e4adbfe42bba99a24106c9da588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9689e11b042d4808be5ccd7be504c0b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "701548eba00a49e699e0b7df0f8844b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f251a1f218d4126b9081add7c746cbb",
              "IPY_MODEL_7004fbbd641843daac3292df2dca5d0e",
              "IPY_MODEL_0e46c03018e840a5ac0d770f01a6f2a2"
            ],
            "layout": "IPY_MODEL_b1d2ffd5a62c48f681a8d70c6efde30c"
          }
        },
        "9f251a1f218d4126b9081add7c746cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b11bf2107914f1fae96dce0e3f41b56",
            "placeholder": "​",
            "style": "IPY_MODEL_c291e1c1515a4e66bdd87decb0a65da8",
            "value": "Downloading: 100%"
          }
        },
        "7004fbbd641843daac3292df2dca5d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7abde2eefbb24a9394272e55e793face",
            "max": 642,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d75c2066b2b46beab72252b2d2f3f3a",
            "value": 642
          }
        },
        "0e46c03018e840a5ac0d770f01a6f2a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7eef9ed9f3e4e7d83021f4b83f82992",
            "placeholder": "​",
            "style": "IPY_MODEL_ec07d55987e44da89351681c30dd77ca",
            "value": " 642/642 [00:00&lt;00:00, 17.2kB/s]"
          }
        },
        "b1d2ffd5a62c48f681a8d70c6efde30c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b11bf2107914f1fae96dce0e3f41b56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c291e1c1515a4e66bdd87decb0a65da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7abde2eefbb24a9394272e55e793face": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d75c2066b2b46beab72252b2d2f3f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7eef9ed9f3e4e7d83021f4b83f82992": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec07d55987e44da89351681c30dd77ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54d999ce39524853b4b6a98551be4f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a32f689bd484f5f88b654b2a7c789a6",
              "IPY_MODEL_d6a564dd9f4b438885557081ffce15c7",
              "IPY_MODEL_df98149c75e14e929927779b2e1e1920"
            ],
            "layout": "IPY_MODEL_99577f53038140c38c45ba78a98b2b69"
          }
        },
        "4a32f689bd484f5f88b654b2a7c789a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cc7dd3bd4e3409db129ccd5ae8a51bd",
            "placeholder": "​",
            "style": "IPY_MODEL_76776e515dd24e0a91315607e87dc56c",
            "value": "Downloading: 100%"
          }
        },
        "d6a564dd9f4b438885557081ffce15c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27f28815c2634b70b36012ab39390ee3",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80a53812d3194ab1a2c393e0f56ca4cd",
            "value": 1042301
          }
        },
        "df98149c75e14e929927779b2e1e1920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81b725631d3a4b60abec19ff7a54916c",
            "placeholder": "​",
            "style": "IPY_MODEL_2c9db389723a45e082272dc09875184c",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 2.90MB/s]"
          }
        },
        "99577f53038140c38c45ba78a98b2b69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc7dd3bd4e3409db129ccd5ae8a51bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76776e515dd24e0a91315607e87dc56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27f28815c2634b70b36012ab39390ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a53812d3194ab1a2c393e0f56ca4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81b725631d3a4b60abec19ff7a54916c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c9db389723a45e082272dc09875184c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c866e0c581b64967a054e9c2c0b8feb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_015063a0440a41d0bf6a1c80b03b8a79",
              "IPY_MODEL_102e6a9605da4f0c918cccb8a639568e",
              "IPY_MODEL_bfa39671e53e48cebe0eadfebbb796a0"
            ],
            "layout": "IPY_MODEL_d9eb9921de154899923576af9fdf4bc0"
          }
        },
        "015063a0440a41d0bf6a1c80b03b8a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00c24ee2927b4f58b4b0deac1e21144b",
            "placeholder": "​",
            "style": "IPY_MODEL_62113956310c443e8d0b22840e8216c4",
            "value": "Downloading: 100%"
          }
        },
        "102e6a9605da4f0c918cccb8a639568e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5fe6934c6974ce8a1a88352024d8e3d",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d09233af4474080b04548ef1383c4a9",
            "value": 456318
          }
        },
        "bfa39671e53e48cebe0eadfebbb796a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79beaf4247054ac98066186fe58a1e63",
            "placeholder": "​",
            "style": "IPY_MODEL_3080554356774259aaee83a245c16431",
            "value": " 456k/456k [00:00&lt;00:00, 929kB/s]"
          }
        },
        "d9eb9921de154899923576af9fdf4bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00c24ee2927b4f58b4b0deac1e21144b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62113956310c443e8d0b22840e8216c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5fe6934c6974ce8a1a88352024d8e3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d09233af4474080b04548ef1383c4a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79beaf4247054ac98066186fe58a1e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3080554356774259aaee83a245c16431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd2b0f44c61343f7a5ea4c5fa2ebcc3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1dadf8c39e274648a4f99b359a8e6b16",
              "IPY_MODEL_531e2d45dfe24d7db400492d986eaa21",
              "IPY_MODEL_6e7e320fdfcc426bb7b558c3725b26b7"
            ],
            "layout": "IPY_MODEL_ac1469acf94b4126b72b0678374f8e53"
          }
        },
        "1dadf8c39e274648a4f99b359a8e6b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27b0bd503c6945b298fcfc8cd259f184",
            "placeholder": "​",
            "style": "IPY_MODEL_8218f7c703324605bf1ad81c4caa10d8",
            "value": "Downloading: 100%"
          }
        },
        "531e2d45dfe24d7db400492d986eaa21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44d93b6c281a46d8a77c1eb55dafea1e",
            "max": 1752292117,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5eff7b42343047fea80e0dd5e758897e",
            "value": 1752292117
          }
        },
        "6e7e320fdfcc426bb7b558c3725b26b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbaf2b14034547a69f076618f4efb85c",
            "placeholder": "​",
            "style": "IPY_MODEL_b6067e28cf7945369739fc19111421e8",
            "value": " 1.75G/1.75G [00:45&lt;00:00, 43.3MB/s]"
          }
        },
        "ac1469acf94b4126b72b0678374f8e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27b0bd503c6945b298fcfc8cd259f184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8218f7c703324605bf1ad81c4caa10d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44d93b6c281a46d8a77c1eb55dafea1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eff7b42343047fea80e0dd5e758897e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbaf2b14034547a69f076618f4efb85c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6067e28cf7945369739fc19111421e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heejookang-sguniv/NLP-/blob/main/120220107%EA%B0%95%ED%9D%AC%EC%A3%BC_DialoGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DialoGPT : Large-scale pretraining for dialogue\n",
        "\n",
        "120220107 강희주 "
      ],
      "metadata": {
        "id": "CES6sLYccf_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Introduction \n",
        "\n",
        "DialogGPT는 conversational neural response generation을 다루기 위해 GPT-2를 확장한다. neural response generation은 자연스럽게 보이는 텍스트를 생성한다는 목표를 공유하는 text-generation의 하위분야이다. \n",
        "\n",
        "GPT-2와 같이 DialoGPT는 autoregressive(AR) language model이며 모델 구성으로 multi-layer transformer를 사용한다. 그러나 GPT-2와 다르게 Reddit discussion chain에서 추출된 대규모 대화 pairs/sessions 에서 학습된다. 논문에서의 의도는 이 대규모 대화 pairs/sessions이 DialogGPT가 대화 플로우에서 $P(Target, Source)$에 대한 joint distribution을 캡쳐할 수 있게 하고자 한다는 것이다. "
      ],
      "metadata": {
        "id": "3xnJF_8Gcf40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset\n",
        "\n",
        "데이터셋은 2005년부터 2017년에 걸쳐 Reddit에서 스크랩된 comment chain에서 추출된다. 스레드에 대한 응답 스레드는 하위 스레드의 루트 노드(root node)를 형성하기 때문에 Reddit discussion은 자연스럽게 tree-structured한 응답 체인으로 펼쳐질 수 있다. 논문에서 root node에서 leaf node까지의 각각의 path(하위 스레드)를 대화의 멀티턴을 가진 학습 인스턴스로 사용한다. \n",
        "\n",
        "아래 기준에 해당하는 데이터를 필터링한다.\n",
        "\n",
        "\n",
        "\n",
        "1.   URL이 있는 source나 target\n",
        "2.   3개 이상의 단어 반복이 target에 포함된 경우\n",
        "3.   응답이 가장 자주 사용하는 top 50 단어(a, the, of 등)가 적어도 하나 이상 포함되지 않은 경우 \n",
        "4.   응답에 [\"또는\"] 이 포함된 경우\n",
        "5.   source와 target 시퀀스가 합쳐서 200단어보다 긴 경우\n",
        "6.   target이 offensive language를 포함한 경우\n",
        "7.   하위 레딧에 많은 수가 offensive한 내용을 포함할 가능성이 많다고 인식되는 경우\n",
        "8.   단조로운 문장 적극적으로 배제 \n",
        "\n",
        "\n",
        "필터링 후 데이터 세트는 총 18억 개의 단어로 147,116,725개의 대화 인스턴스로 구성된다. \n",
        "\n"
      ],
      "metadata": {
        "id": "La0JW4hBcftx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPT-2 \n",
        "\n",
        "GPT-2는 transformer의 decoder 블럭으로 구성된다. decoder block에 입력되는 입력벡터는 각 디코더셀의 self-attention 과정을 거친 뒤, 신경망 레이어를 지난다. 모든 디코더 블럭을 거친 최종 결과물은 입력값에 대한 최종 셀프 어텐션 값을 가지고 있다. 이를 우리가 가진 임베딩 벡터와 곱해주면, 각 단어가 다음 단어로 등장할 확률값이 나오게 된다. 이 중에서 가장 확률값이 높은 것이 출력값이 되며, 또 다음의 입력값이 된다. "
      ],
      "metadata": {
        "id": "ZqwfyQ-atkKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Method\n",
        "\n",
        "###3.1 Model architecture\n",
        "\n",
        "우리는 첫 번째로 대화세션 안에서 모든 대화 turns을 concat 시켜 긴 text $x_1, ..., x_N$($N$은 시퀀스 길이)를 만들고 끝에는 end-of-text-token을 넣는다. \n",
        "\n",
        "source sentence(대화 히스토리)는 $S = x_1, ..., x_m$으로 표기하고 target sentence (ground truth response)는 $T = x_{m+1}, ..., x_N$으로 표기한다. \n",
        "\n",
        "이때, 조건부 확률 $P(T|S)$은 조건부 확률의 일련의 곱으로 아래의 식과 같이 쓰여진다. \n",
        "\n",
        "\n",
        "$p(T|s) = \\prod_{n = m+1}^N p(x_n | x_1,..., x_{n-1}) $\n",
        "\n",
        "\n",
        "DialoGPT는 GPT-2를 따라 multi-turn dialogue를 하나의 text로 간주한다. 따라서 multi-turn dialogue session인 $T_1, ..., T_k$은 $p(T_k, ..., T_2|T_1)$로 볼 수 있고 이는 사실 $p(T_i|T_1,...,T_{i-1})$ (여기서 $i$는 $m+1$) 조건부 확률을 product한 것이다. 결과적으로 $p(T_k, ..., T_2|T_1)$을 최적화하는 것은 모든 $p(T_I | T_1, ..., T_{i-1})$ source-target 페어를 최적화하는 것이다.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zOox7kQhhHpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2 Mutual Information Maximization \n",
        "\n",
        "*   $\\hat{T} = argmax_T(log$ $p(T|S)$)\n",
        "\n",
        "     위의 공식처럼 일반적인 likelihood는 'I don't know, i'm ok'와 같이 어정쩡한 응답을 생성하게 한다고 추측한다. 이 공식은 target에서 source가 아닌 source에서 target에 대해서만 선택하기 때문이다. 오픈 도메인 텍스트 생성 모델의 bland하고 uninformative 함을 해결하기 위해, objective function을 maximum mutual information(MMI) scoring function으로 대체한다. MMI에서 파라미터는 아래의 공식처럼 source $S$와 target $T$간에 상호 정보(mutual information)를 최대화하도록 학습된다. \n",
        "\n",
        "    $\\hat{T} = argmax_{T}((1-\\lambda)log$ $p(T|S) + \\lambda log$ $p(S|T))$\n",
        "\n",
        "\n",
        "\n",
        "*   MMI는 pre-trained backward model(pre-trained language model)을 활용하여 주어진 응답에 대해 source sentence를 예측한다(ex. $P(Source|target)$). 먼저 top-K 샘플링을 사용하여 hypotheses 셋을 생성한다($P(Hypothesis|Source)$). 그리고 모든 hypotheses를 re-rank 하기 위해 $P(Source|Hypothesis)$ 조건부 확률을 사용한다. 직관적으로 backward model(pre-trained model)likelihood를 최대화하는 것은 bland hypotheses에 불이익을 준다. bland 한 hypotheses는 많은 source query이 가능하기 때문에 모든 쿼리에 대해 확률값이 낮아지기 때문이다. 따라서 특정 쿼리에 대해 높은 확률 값을 가지지 않게 된다. \n",
        "\n"
      ],
      "metadata": {
        "id": "cnhhTUx1qCK0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd9uy9p6cagd"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "###############################################\n",
        "#트랜스포머의 디코더 블록 구현\n",
        "###############################################\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, hidden_size, eps=1e-12):\n",
        "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
        "        \"\"\"\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.variance_epsilon = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = x.mean(-1, keepdim=True)\n",
        "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "        return self.weight * x + self.bias\n",
        "\n",
        "class Conv1D(nn.Module):\n",
        "    def __init__(self, nf, nx):\n",
        "        super(Conv1D, self).__init__()\n",
        "        self.nf = nf\n",
        "        w = torch.empty(nx, nf)\n",
        "        nn.init.normal_(w, std=0.02)\n",
        "        self.weight = Parameter(w)\n",
        "        self.bias = Parameter(torch.zeros(nf))\n",
        "\n",
        "    def forward(self, x):\n",
        "        size_out = x.size()[:-1] + (self.nf,)\n",
        "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
        "        x = x.view(*size_out)\n",
        "        return x\n",
        "\n",
        "####################################################\n",
        "#multi-head masked self-attention 구현 \n",
        "####################################################\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, nx, n_ctx, config, scale=False):\n",
        "        super(Attention, self).__init__()\n",
        "        n_state = nx  # in Attention: n_state=768 (nx=n_embd)\n",
        "        # [switch nx => n_state from Block to Attention to keep identical to TF implem]\n",
        "        assert n_state % config.n_head == 0\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
        "        self.n_head = config.n_head\n",
        "        self.split_size = n_state\n",
        "        self.scale = scale\n",
        "        self.c_attn = Conv1D(n_state * 3, nx)\n",
        "        self.c_proj = Conv1D(n_state, nx)\n",
        "\n",
        "    def _attn(self, q, k, v):\n",
        "        w = torch.matmul(q, k)\n",
        "        if self.scale:\n",
        "            w = w / math.sqrt(v.size(-1))\n",
        "        nd, ns = w.size(-2), w.size(-1)\n",
        "        b = self.bias[:, :, ns-nd:ns, :ns]\n",
        "        w = w * b - 1e10 * (1 - b)\n",
        "        w = nn.Softmax(dim=-1)(w)\n",
        "        return torch.matmul(w, v)\n",
        "\n",
        "    def merge_heads(self, x):\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        new_x_shape = x.size()[:-2] + (x.size(-2) * x.size(-1),)\n",
        "        return x.view(*new_x_shape)  # in Tensorflow implem: fct merge_states\n",
        "\n",
        "    def split_heads(self, x, k=False):\n",
        "        new_x_shape = x.size()[:-1] + (self.n_head, x.size(-1) // self.n_head)\n",
        "        x = x.view(*new_x_shape)  # in Tensorflow implem: fct split_states\n",
        "        if k:\n",
        "            return x.permute(0, 2, 3, 1)  # (batch, head, head_features, seq_length)\n",
        "        else:\n",
        "            return x.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
        "\n",
        "    def forward(self, x, layer_past=None):\n",
        "        x = self.c_attn(x)\n",
        "        query, key, value = x.split(self.split_size, dim=2)\n",
        "        query = self.split_heads(query)\n",
        "        key = self.split_heads(key, k=True)\n",
        "        value = self.split_heads(value)\n",
        "        if layer_past is not None:\n",
        "            past_key, past_value = layer_past[0].transpose(-2, -1), layer_past[1]  # transpose back cf below\n",
        "            key = torch.cat((past_key, key), dim=-1)\n",
        "            value = torch.cat((past_value, value), dim=-2)\n",
        "        present = torch.stack((key.transpose(-2, -1), value))  # transpose to have same shapes for stacking\n",
        "        a = self._attn(query, key, value)\n",
        "        a = self.merge_heads(a)\n",
        "        a = self.c_proj(a)\n",
        "        return a, present\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, n_state, config):  # in MLP: n_state=3072 (4 * n_embd)\n",
        "        super(MLP, self).__init__()\n",
        "        nx = config.n_embd\n",
        "        self.c_fc = Conv1D(n_state, nx)\n",
        "        self.c_proj = Conv1D(nx, n_state)\n",
        "        self.act = gelu\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.act(self.c_fc(x))\n",
        "        h2 = self.c_proj(h)\n",
        "        return h2\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_ctx, config, scale=False):\n",
        "        super(Block, self).__init__()\n",
        "        nx = config.n_embd\n",
        "        self.ln_1 = LayerNorm(nx, eps=config.layer_norm_epsilon)\n",
        "        self.attn = Attention(nx, n_ctx, config, scale)\n",
        "        self.ln_2 = LayerNorm(nx, eps=config.layer_norm_epsilon)\n",
        "        self.mlp = MLP(4 * nx, config)\n",
        "\n",
        "    def forward(self, x, layer_past=None):\n",
        "        a, present = self.attn(self.ln_1(x), layer_past=layer_past)\n",
        "        x = x + a\n",
        "        m = self.mlp(self.ln_2(x))\n",
        "        x = x + m\n",
        "        return x, present\n",
        "\n",
        "class GPT2Model(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(GPT2Model, self).__init__()\n",
        "        self.n_layer = config.n_layer\n",
        "        self.n_embd = config.n_embd\n",
        "        self.n_vocab = config.vocab_size\n",
        "\n",
        "        self.wte = nn.Embedding(config.vocab_size, config.n_embd)\n",
        "        self.wpe = nn.Embedding(config.n_positions, config.n_embd)\n",
        "        block = Block(config.n_ctx, config, scale=True)\n",
        "        self.h = nn.ModuleList([copy.deepcopy(block) for _ in range(config.n_layer)])\n",
        "        self.ln_f = LayerNorm(config.n_embd, eps=config.layer_norm_epsilon)\n",
        "\n",
        "    def set_embeddings_weights(self, model_embeddings_weights):\n",
        "        embed_shape = model_embeddings_weights.shape\n",
        "        self.decoder = nn.Linear(embed_shape[1], embed_shape[0], bias=False)\n",
        "        self.decoder.weight = model_embeddings_weights  # Tied weights\n",
        "\n",
        "    def forward(self, input_ids, position_ids=None, token_type_ids=None, past=None):\n",
        "        if past is None:\n",
        "            past_length = 0\n",
        "            past = [None] * len(self.h)\n",
        "        else:\n",
        "            past_length = past[0][0].size(-2)\n",
        "        if position_ids is None:\n",
        "            position_ids = torch.arange(past_length, input_ids.size(-1) + past_length, dtype=torch.long,\n",
        "                                        device=input_ids.device)\n",
        "            position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "\n",
        "        input_shape = input_ids.size()\n",
        "        input_ids = input_ids.view(-1, input_ids.size(-1))\n",
        "        position_ids = position_ids.view(-1, position_ids.size(-1))\n",
        "\n",
        "        inputs_embeds = self.wte(input_ids)\n",
        "        position_embeds = self.wpe(position_ids)\n",
        "        if token_type_ids is not None:\n",
        "            token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1))\n",
        "            token_type_embeds = self.wte(token_type_ids)\n",
        "        else:\n",
        "            token_type_embeds = 0\n",
        "\n",
        "        # hidden_states 생성    \n",
        "        hidden_states = inputs_embeds + position_embeds + token_type_embeds\n",
        "        presents = []\n",
        "        \n",
        "        # 디코더 블록에 hidden states 입력\n",
        "        for block, layer_past in zip(self.h, past):\n",
        "            hidden_states, present = block(hidden_states, layer_past)\n",
        "            presents.append(present)\n",
        "        hidden_states = self.ln_f(hidden_states)\n",
        "        output_shape = input_shape + (hidden_states.size(-1),)\n",
        "        return hidden_states.view(*output_shape), presents\n",
        "\n",
        "#디코더 출력으로 토큰 예측 \n",
        "class GPT2LMHead(nn.Module):\n",
        "    def __init__(self, model_embeddings_weights, config):\n",
        "        super(GPT2LMHead, self).__init__()\n",
        "        self.n_embd = config.n_embd\n",
        "        self.set_embeddings_weights(model_embeddings_weights)\n",
        "\n",
        "    def set_embeddings_weights(self, model_embeddings_weights):\n",
        "        embed_shape = model_embeddings_weights.shape\n",
        "        self.decoder = nn.Linear(embed_shape[1], embed_shape[0], bias=False)\n",
        "        self.decoder.weight = model_embeddings_weights  # Tied weights\n",
        "\n",
        "    def forward(self, hidden_state):\n",
        "        # Truncated Language modeling logits (we remove the last token)\n",
        "        # h_trunc = h[:, :-1].contiguous().view(-1, self.n_embd)\n",
        "        lm_logits = self.decoder(hidden_state)\n",
        "        return lm_logits\n",
        "\n",
        "class GPT2LMHeadModel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(GPT2LMHeadModel, self).__init__()\n",
        "        self.transformer = GPT2Model(config)\n",
        "        self.lm_head = GPT2LMHead(self.transformer.wte.weight, config)\n",
        "\n",
        "    def set_tied(self):\n",
        "        \"\"\" Make sure we are sharing the embeddings\n",
        "        \"\"\"\n",
        "        self.lm_head.set_embeddings_weights(self.transformer.wte.weight)\n",
        "\n",
        "    def forward(self, input_ids, position_ids=None, token_type_ids=None, lm_labels=None, past=None):\n",
        "        #GPT model에 시퀀스 입력 후 hidden_states를 얻음. hidden states로 부터 다음 토큰의 분포 예측 \n",
        "        hidden_states, presents = self.transformer(input_ids, position_ids, token_type_ids, past)\n",
        "        lm_logits = self.lm_head(hidden_states)\n",
        "        if lm_labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "            loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), lm_labels.view(-1))\n",
        "            return loss\n",
        "        return lm_logits, presents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lsp_model import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, Adam\n",
        "from gpt2_training.train_utils import load_model, boolean_string, set_lr, get_eval_list_same_length\n",
        "from gpt2_training.eval_utils import eval_model_loss\n",
        "\n",
        "from data_loader import BucketingDataLoader, DynamicBatchingLoader, DistributedBucketingDataLoader\n",
        "\n",
        "\n",
        "from gpt2_training.distributed import all_reduce_and_rescale_tensors, all_gather_list\n",
        "\n",
        "\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "    datefmt='%m/%d/%Y %H:%M:%S', level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "INF = 100000000\n",
        "CACHE_EMPTY_STEP = 10000\n",
        "EVAL_STEP = 100000\n",
        "\n",
        "#########################################################################\n",
        "# Prepare Parser\n",
        "##########################################################################\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model_name_or_path', type=str,\n",
        "                    help='pretrained model name or path to local checkpoint')\n",
        "parser.add_argument(\"--seed\", type=int, default=42)\n",
        "parser.add_argument(\"--max_seq_length\", type=int, default=128)\n",
        "\n",
        "parser.add_argument(\"--skip_eval\", action='store_true',\n",
        "                    help='If true, skip evaluation.')\n",
        "parser.add_argument(\"--init_checkpoint\", type=str)\n",
        "parser.add_argument(\"--train_input_file\", type=str)\n",
        "parser.add_argument(\"--eval_input_file\", type=str)\n",
        "parser.add_argument(\"--continue_from\", type=int, default=0)\n",
        "\n",
        "parser.add_argument(\"--train_batch_size\", type=int, default=4,\n",
        "                    help=\"batch size now means per GPU per step\")\n",
        "parser.add_argument(\"--gradient_accumulation_steps\", type=int, default=2,\n",
        "                    help=\"to increase effective batch size \"\n",
        "                         \"and reduce synchronization\")\n",
        "parser.add_argument(\"--eval_batch_size\", type=int, default=4)\n",
        "parser.add_argument(\"--learning_rate\", type=float, default=1e-5)\n",
        "parser.add_argument(\"--num_optim_steps\", type=int, default=1000000,\n",
        "                    help=\"new API specifies num update steps\")\n",
        "parser.add_argument(\"--valid_step\", type=int, default=10000,\n",
        "                    help=\"how many optim steps between validations\")\n",
        "parser.add_argument(\"--warmup_proportion\", type=float, default=0.1)\n",
        "parser.add_argument(\"--warmup_steps\", type=int, default=16000)\n",
        "\n",
        "parser.add_argument(\"--normalize_data\", type=boolean_string, default=True)\n",
        "parser.add_argument(\"--fp16\", type=boolean_string, default=True)\n",
        "parser.add_argument(\"--lr_schedule\", type=str,\n",
        "                    choices=['noam', 'noamwd', 'BERT', 'None'], default='noam')\n",
        "parser.add_argument(\"--loss_scale\", type=float, default=0)\n",
        "parser.add_argument(\"--no_token_id\", type=boolean_string, default=True)\n",
        "\n",
        "parser.add_argument(\"--output_dir\", type=str)\n",
        "parser.add_argument(\"--log_dir\", type=str)\n",
        "parser.add_argument('--pbar', type=boolean_string, default=True, help='turn on progress bar')\n",
        "\n",
        "# distributed\n",
        "parser.add_argument('--local_rank', type=int, default=-1,\n",
        "                    help='for torch.distributed')\n",
        "parser.add_argument('--config', help='JSON config file')\n",
        "\n",
        "\n",
        "# 정상적인 구문 분석을 수행\n",
        "args = parser.parse_args()\n",
        "\n",
        "if args.config is not None:\n",
        "    # config JSON으로 argparse 기본값 재정의\n",
        "    opts = json.load(open(args.config))\n",
        "    for k, v in opts.items():\n",
        "        if isinstance(v, str):\n",
        "            # PHILLY ENV special cases\n",
        "            if 'PHILLY_JOB_DIRECTORY' in v:\n",
        "                v = v.replace('PHILLY_JOB_DIRECTORY',\n",
        "                              os.environ['PHILLY_JOB_DIRECTORY'])\n",
        "            elif 'PHILLY_LOG_DIRECTORY' in v:\n",
        "                v = v.replace('PHILLY_LOG_DIRECTORY',\n",
        "                              os.environ['PHILLY_LOG_DIRECTORY'])\n",
        "        setattr(args, k, v)\n",
        "\n",
        "    # command line은 config JSON을 재정의해야한다. \n",
        "    argv = sys.argv[1:]\n",
        "    overrides, _ = parser.parse_known_args(argv)\n",
        "    for k, v in vars(overrides).items():\n",
        "        if f'--{k}' in argv:\n",
        "            setattr(args, k, v)\n",
        "    setattr(args, 'local_rank', overrides.local_rank)\n",
        "\n",
        "\n",
        "assert args.train_batch_size % args.gradient_accumulation_steps == 0, \\\n",
        "    'batch size % gradient accumulation steps != 0!'\n",
        "args.train_batch_size = (args.train_batch_size\n",
        "                         // args.gradient_accumulation_steps)\n",
        "logger.info('train batch size = {}, '\n",
        "            'new train batch size (after gradient accumulation) = {}'.format(\n",
        "                args.train_batch_size*args.gradient_accumulation_steps,\n",
        "                args.train_batch_size))\n",
        "\n",
        "\n",
        "if args.local_rank == -1:\n",
        "    logger.info('CUDA available? {}'.format(str(torch.cuda.is_available())))\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    args.device, args.n_gpu = device, n_gpu\n",
        "else:\n",
        "    # distributed training\n",
        "    torch.cuda.set_device(args.local_rank)\n",
        "    device = torch.device(\"cuda\", args.local_rank)\n",
        "    #동기화 node/GPU를 처리할 distributed backend를 초기화한다. \n",
        "    torch.distributed.init_process_group(backend='nccl')\n",
        "    n_gpu = torch.distributed.get_world_size()\n",
        "    args.device, args.n_gpu = device, 1\n",
        "    logger.info(\"device: {} n_gpu: {}, distributed training: {}, \"\n",
        "                \"16-bits training: {}\".format(\n",
        "                    device, n_gpu, bool(args.local_rank != -1), args.fp16))\n",
        "\n",
        "np.random.seed(args.seed)\n",
        "torch.random.manual_seed(args.seed)\n",
        "torch.cuda.manual_seed(args.seed)\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime('%Y-%m-%d%H%M%S')\n",
        "output_dir = join(args.output_dir,\n",
        "                  'GPT2.{}.{}.{}gpu.{}'.format(args.learning_rate,\n",
        "                                               args.train_batch_size, n_gpu,\n",
        "                                               timestamp))\n",
        "log_dir = args.log_dir if args.log_dir is not None and len(args.log_dir) > 0 else output_dir\n",
        "if args.local_rank == -1 or get_rank() == 0:\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "logger.info('Input Argument Information')\n",
        "args_dict = vars(args)\n",
        "for a in args_dict:\n",
        "    logger.info('%-28s  %s' % (a, args_dict[a]))\n",
        "\n",
        "\n",
        "#########################################################################\n",
        "# 데이터셋 준비\n",
        "##########################################################################\n",
        "enc = GPT2Tokenizer.from_pretrained(args.model_name_or_path)\n",
        "\n",
        "config = GPT2Config.from_json_file(\n",
        "    join(args.model_name_or_path, 'config.json'))\n",
        "\n",
        "if args.local_rank == -1:\n",
        "    train_dataloader = BucketingDataLoader(args.train_input_file,\n",
        "                                           args.train_batch_size,\n",
        "                                           args.max_seq_length)\n",
        "else:\n",
        "    train_dataloader = DistributedBucketingDataLoader(\n",
        "        get_rank(), get_world_size(),\n",
        "        args.train_input_file, args.train_batch_size,\n",
        "        args.max_seq_length)\n",
        "\n",
        "eval_dataloader_loss = DynamicBatchingLoader(\n",
        "    args.eval_input_file, enc, args.normalize_data,\n",
        "    args.eval_batch_size, args.max_seq_length)\n",
        "\n",
        "eval_dataloader_gen = get_eval_list_same_length(\n",
        "    args.eval_input_file, enc, args.eval_batch_size, True)\n",
        "\n",
        "\n",
        "#########################################################################\n",
        "# 모델 및 옵티마이저 준비\n",
        "##########################################################################\n",
        "model = load_model(GPT2LMHeadModel(config), args.init_checkpoint,\n",
        "                   args, verbose=True)\n",
        "if args.local_rank != -1:\n",
        "    # 처음부터 초기 모델이 동일한지 확인 \n",
        "    params = [p.data for p in model.parameters()]\n",
        "    all_reduce_and_rescale_tensors(\n",
        "        params, float(torch.distributed.get_world_size()))\n",
        "\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "total_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "logger.info('Number of parameter = {}'.format(total_params))\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'ln']   # no decay for bias and LayerNorm (ln)\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer\n",
        "                if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer\n",
        "                if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "if args.fp16:\n",
        "    logger.info('in fp16, using FusedAdam')\n",
        "    try:\n",
        "        from apex.optimizers import FP16_Optimizer\n",
        "        from apex.optimizers import FusedAdam\n",
        "    except ImportError:\n",
        "        raise ImportError(\n",
        "            \"Please install apex from https://www.github.com/nvidia/apex \"\n",
        "            \"to use distributed and fp16 training.\")\n",
        "\n",
        "    optimizer = FusedAdam(optimizer_grouped_parameters,\n",
        "                          lr=args.learning_rate,\n",
        "                          bias_correction=False,\n",
        "                          max_grad_norm=1.0)\n",
        "    if args.loss_scale == 0:\n",
        "        optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True,\n",
        "                                   verbose=False)\n",
        "    else:\n",
        "        optimizer = FP16_Optimizer(optimizer,\n",
        "                                   static_loss_scale=args.loss_scale,\n",
        "                                   verbose=False)\n",
        "else:\n",
        "    optimizer = Adam(optimizer_grouped_parameters, args.learning_rate,\n",
        "                     max_grad_norm=1.0)\n",
        "\n",
        "#########################################################################\n",
        "# 학습\n",
        "##########################################################################\n",
        "\n",
        "if args.local_rank == -1 or get_rank() == 0:\n",
        "    train_logger = open(join(log_dir, 'train_log.txt'), 'a+', buffering=1)\n",
        "    eval_logger = open(join(log_dir, 'eval_log.txt'), 'a+', buffering=1)\n",
        "    print('epoch,global_step,step,mean_loss,mean_ppl,n_token_real,'\n",
        "          'n_token_total,epoch_time', file=train_logger)\n",
        "    print('epoch,global_step,step,eval_loss,eval_ppl', file=eval_logger)\n",
        "\n",
        "global_step = 0\n",
        "step = 0\n",
        "epoch = 0\n",
        "\n",
        "if args.continue_from:\n",
        "    global_step = args.continue_from\n",
        "    step = global_step*2 - 1\n",
        "\n",
        "\n",
        "if args.local_rank != -1:\n",
        "    n_gpu = 1\n",
        "if args.local_rank == -1 or get_rank() == 0:\n",
        "    if args.pbar:\n",
        "        pbar = tqdm.tqdm(total=args.num_optim_steps, desc=f\"training\")\n",
        "    else:\n",
        "        pbar = None\n",
        "\n",
        "while True:\n",
        "    model.train()\n",
        "    (tr_loss, tr_ppl, mean_ppl, nb_tr_examples, nb_tr_steps) = 0.0, 0.0, 0.0, 0, 0\n",
        "    n_token_real, n_token_total = 0, 0\n",
        "    train_start_time_epoch = time.time()\n",
        "    for batch in train_dataloader:\n",
        "        # 새로운 훈련 모드 활성화\n",
        "        seq_len = batch[0].shape[1]\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, position_ids, token_ids, label_ids, *_ = batch\n",
        "        if args.no_token_id:\n",
        "            token_ids = None\n",
        "        loss, ppl = model(input_ids, position_ids, token_ids, label_ids)\n",
        "\n",
        "        if n_gpu > 1:\n",
        "            loss = loss.mean()\n",
        "            ppl = ppl.mean()\n",
        "        loss = loss / (args.train_batch_size / input_ids.shape[0])\n",
        "        if args.fp16:\n",
        "            optimizer.backward(loss)\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        tr_loss += float(loss.item()) * (args.train_batch_size / input_ids.shape[0])\n",
        "        nb_tr_examples += input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        mean_loss = tr_loss / nb_tr_steps\n",
        "        if ppl.item() < INF:\n",
        "            tr_ppl += ppl.item()\n",
        "        else:\n",
        "            tr_ppl += mean_ppl\n",
        "        mean_ppl = tr_ppl / nb_tr_steps\n",
        "\n",
        "        n_token_total += input_ids.shape[0] * input_ids.shape[1]\n",
        "        n_token_real += (input_ids != 0).sum().item()\n",
        "\n",
        "        # 그래디언트 업데이트 \n",
        "        step += 1\n",
        "        if step % args.gradient_accumulation_steps == 0:\n",
        "            set_lr(optimizer, global_step,\n",
        "                   args.lr_schedule, args.learning_rate,\n",
        "                   args.warmup_steps, args.warmup_proportion,\n",
        "                   config.n_embd, args.num_optim_steps)\n",
        "\n",
        "            if args.local_rank != -1:\n",
        "                grads = [p.grad.data for p in model.parameters()\n",
        "                         if p.requires_grad and p.grad is not None]\n",
        "                all_reduce_and_rescale_tensors(grads, float(1))\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1\n",
        "\n",
        "            # Print log info to file\n",
        "            if args.local_rank != -1:\n",
        "                mean_loss = sum(all_gather_list(mean_loss)) / get_world_size()\n",
        "                mean_ppl = sum(all_gather_list(mean_ppl)) / get_world_size()\n",
        "                n_token_real_all_proc = sum(all_gather_list(n_token_real))\n",
        "                n_token_total_all_proc = sum(all_gather_list(n_token_total))\n",
        "            else:\n",
        "                n_token_real_all_proc = n_token_real\n",
        "                n_token_total_all_proc = n_token_total\n",
        "\n",
        "            if args.local_rank == -1 or get_rank() == 0:\n",
        "                epoch_time = time.time() - train_start_time_epoch\n",
        "                if pbar is not None:\n",
        "                    pbar.set_postfix_str(\n",
        "                        f\"tok/s: {n_token_real_all_proc//epoch_time//1000}k \"\n",
        "                        f\"ppl: {mean_ppl:.2f} epoch: {epoch}\")\n",
        "                    pbar.update(1)\n",
        "                print('{},{},{},{},{},{},{},{}'.format(\n",
        "                    epoch+1, global_step+1, step+1, mean_loss, mean_ppl,\n",
        "                    n_token_real_all_proc, n_token_total_all_proc, epoch_time),\n",
        "                    file=train_logger)\n",
        "\n",
        "            if global_step % args.valid_step == 0:\n",
        "                if args.local_rank == -1 or get_rank() == 0:\n",
        "                    # 오직 rank가 0인 프로세스만 evaluate 한다. \n",
        "                    torch.save(\n",
        "                        {k: (v.cpu() if v is not None else None)  # save to cpu tensors\n",
        "                         for k, v in model.state_dict().items()},\n",
        "                        join(output_dir,\n",
        "                             f'GP2-pretrain-step-{global_step}.pkl'))\n",
        "\n",
        "                    eval_loss, eval_ppl = eval_model_loss(\n",
        "                        model, enc, eval_dataloader_loss, epoch, args)\n",
        "                    # enable generation step evaluation for now\n",
        "                    # gen_response = eval_model_generation(\n",
        "                    #     model, enc, eval_dataloader_gen, epoch, args)\n",
        "                    '''\n",
        "                    # probably use beam search only for test set\n",
        "                    if False:\n",
        "                        gen_response_beam = eval_model_generation(\n",
        "                            model, enc, eval_dataloader_gen, epoch, args,\n",
        "                            use_beam_search=True, beam_width=3)\n",
        "                    '''\n",
        "                    print('{},{},{},{},{}'.format(\n",
        "                        epoch+1, global_step+1, step+1, eval_loss, eval_ppl),\n",
        "                        file=eval_logger)\n",
        "                    logger.info('current learning rate: '\n",
        "                                + str(optimizer.param_groups[0]['lr']))\n",
        "                    model.train()\n",
        "            if global_step >= args.num_optim_steps:\n",
        "                break\n",
        "\n",
        "        if (step+1) % CACHE_EMPTY_STEP == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    if global_step >= args.num_optim_steps:\n",
        "        break\n",
        "    epoch += 1\n",
        "\n",
        "\n",
        "if args.local_rank == -1 or get_rank() == 0:\n",
        "    if pbar is not None:\n",
        "        pbar.close()\n",
        "    train_logger.close()\n",
        "    eval_logger.close()"
      ],
      "metadata": {
        "id": "UexPz4M_zLs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GVxRNsx2leW",
        "outputId": "b3aa24ca-010c-4a84-f75f-a227f9f44529"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 57.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 28.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "model = AutoModelWithLMHead.from_pretrained(\"microsoft/DialoGPT-large\")\n",
        "\n",
        "# Let's chat for 5 lines\n",
        "for step in range(5):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
        "\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens, \n",
        "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # pretty print last ouput tokens from bot\n",
        "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509,
          "referenced_widgets": [
            "85898e3c2ae74b6f8e8198ff15b9f09d",
            "0d1c013f3e9f456cb8e9801e119027aa",
            "3bb7bf9be2674494842ad6b726d1f61d",
            "8295191b1da1436e95f15eb5edd14c98",
            "96f914e5c5d64de48ecaa0b1eeac2a03",
            "db169823b7f24168857cf22eee1fea74",
            "ea3607e5e36b4f8dbd9b07f0ed953ff0",
            "2ca22facc1264260958e09346feefd56",
            "aeb5e47bed2f460db7b17ed84b9776a5",
            "e91d9e4adbfe42bba99a24106c9da588",
            "9689e11b042d4808be5ccd7be504c0b6",
            "701548eba00a49e699e0b7df0f8844b0",
            "9f251a1f218d4126b9081add7c746cbb",
            "7004fbbd641843daac3292df2dca5d0e",
            "0e46c03018e840a5ac0d770f01a6f2a2",
            "b1d2ffd5a62c48f681a8d70c6efde30c",
            "2b11bf2107914f1fae96dce0e3f41b56",
            "c291e1c1515a4e66bdd87decb0a65da8",
            "7abde2eefbb24a9394272e55e793face",
            "8d75c2066b2b46beab72252b2d2f3f3a",
            "a7eef9ed9f3e4e7d83021f4b83f82992",
            "ec07d55987e44da89351681c30dd77ca",
            "54d999ce39524853b4b6a98551be4f67",
            "4a32f689bd484f5f88b654b2a7c789a6",
            "d6a564dd9f4b438885557081ffce15c7",
            "df98149c75e14e929927779b2e1e1920",
            "99577f53038140c38c45ba78a98b2b69",
            "5cc7dd3bd4e3409db129ccd5ae8a51bd",
            "76776e515dd24e0a91315607e87dc56c",
            "27f28815c2634b70b36012ab39390ee3",
            "80a53812d3194ab1a2c393e0f56ca4cd",
            "81b725631d3a4b60abec19ff7a54916c",
            "2c9db389723a45e082272dc09875184c",
            "c866e0c581b64967a054e9c2c0b8feb1",
            "015063a0440a41d0bf6a1c80b03b8a79",
            "102e6a9605da4f0c918cccb8a639568e",
            "bfa39671e53e48cebe0eadfebbb796a0",
            "d9eb9921de154899923576af9fdf4bc0",
            "00c24ee2927b4f58b4b0deac1e21144b",
            "62113956310c443e8d0b22840e8216c4",
            "f5fe6934c6974ce8a1a88352024d8e3d",
            "8d09233af4474080b04548ef1383c4a9",
            "79beaf4247054ac98066186fe58a1e63",
            "3080554356774259aaee83a245c16431",
            "cd2b0f44c61343f7a5ea4c5fa2ebcc3a",
            "1dadf8c39e274648a4f99b359a8e6b16",
            "531e2d45dfe24d7db400492d986eaa21",
            "6e7e320fdfcc426bb7b558c3725b26b7",
            "ac1469acf94b4126b72b0678374f8e53",
            "27b0bd503c6945b298fcfc8cd259f184",
            "8218f7c703324605bf1ad81c4caa10d8",
            "44d93b6c281a46d8a77c1eb55dafea1e",
            "5eff7b42343047fea80e0dd5e758897e",
            "bbaf2b14034547a69f076618f4efb85c",
            "b6067e28cf7945369739fc19111421e8"
          ]
        },
        "id": "yQVwliMK2l-R",
        "outputId": "a4df73a1-4f01-4f06-c201-32a3e8d69e55"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85898e3c2ae74b6f8e8198ff15b9f09d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "701548eba00a49e699e0b7df0f8844b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54d999ce39524853b4b6a98551be4f67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c866e0c581b64967a054e9c2c0b8feb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/modeling_auto.py:1177: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd2b0f44c61343f7a5ea4c5fa2ebcc3a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> User:hi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DialoGPT: hi\n",
            ">> User:how are you\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DialoGPT: I'm good, you?\n",
            ">> User:where are you now\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DialoGPT: I'm in the middle of a battle, I'll be back in a few minutes\n",
            ">> User:what battle?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DialoGPT: I'm in the middle of a battle, I'll be back in a few minutes\n",
            ">> User:what are you doing?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DialoGPT: I'm in the middle of a battle, I'll be back in a few minutes\n"
          ]
        }
      ]
    }
  ]
}